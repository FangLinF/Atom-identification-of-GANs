{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2c1e73",
   "metadata": {},
   "source": [
    "### 1、Import the corresponding library and module of deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9129cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utils import *\n",
    "import time\n",
    "import os\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010039b",
   "metadata": {},
   "source": [
    "### 2、Set some global variables: Learning Rate, Batch Size, Image Size , etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "LEARNING_RATE = 0.0002\n",
    "BATCH_SIZE = 6\n",
    "SHAPE = [256,256,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151dbd96",
   "metadata": {},
   "source": [
    "### 3、Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90cfb6",
   "metadata": {},
   "source": [
    "#### 3.1、Set the file location of training set and verification set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6242c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_img_dir='#########'\n",
    "train_output_img_dir='#########'\n",
    "\n",
    "validation_input_img_dir = '#########'\n",
    "validation_output_img_dir = '#########'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80827098",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_img_dir='#########'\n",
    "train_output_img_dir='#########'\n",
    "\n",
    "validation_input_img_dir = '#########'\n",
    "validation_output_img_dir = '#########'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_img_path = [os.path.join(train_input_img_dir,img) for img in os.listdir(train_input_img_dir)]\n",
    "train_output_img_path = [os.path.join(train_output_img_dir,img) for img in os.listdir(train_output_img_dir)]\n",
    "\n",
    "validation_input_img_path = [os.path.join(validation_input_img_dir,img) for img in os.listdir(validation_input_img_dir)]\n",
    "validation_output_img_path = [os.path.join(validation_output_img_dir,img) for img in os.listdir(validation_output_img_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd54fe",
   "metadata": {},
   "source": [
    "#### 3.2、Show the number of images in the training set and verification set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13964b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_input_img_path))\n",
    "print(len(train_output_img_path))\n",
    "print(len(validation_input_img_path))\n",
    "print(len(validation_output_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3c148",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_input_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001422ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b231544",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_output_img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce7788",
   "metadata": {},
   "source": [
    "#### 3.3、Check the number of channels for the input image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d633067",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_img_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_img_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load(train_input_img_path[0],train_output_img_path[0]))\n",
    "for i in range(15):\n",
    "    input_image, output_image = load(train_input_img_path[i],train_output_img_path[i])\n",
    "    print(input_image.shape,output_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load(validation_input_img_path[0],validation_output_img_path[0]))\n",
    "for i in range(3):\n",
    "    input_image, output_image = load(validation_input_img_path[i],validation_output_img_path[i])\n",
    "    print(input_image.shape,output_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d668f622",
   "metadata": {},
   "source": [
    "#### 3.4、Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4993ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(input_image_file,output_image_file):\n",
    "    \n",
    "    input_image = tf.io.read_file(input_image_file) \n",
    "    input_image = tf.image.decode_jpeg(input_image) \n",
    "    input_image = tf.image.resize(input_image,size=(SHAPE[0],SHAPE[1])) \n",
    "    \n",
    "    \n",
    "    output_image = tf.io.read_file(output_image_file)\n",
    "    output_image = tf.image.decode_jpeg(output_image)\n",
    "    output_image = tf.image.resize(output_image,size=(SHAPE[0],SHAPE[1]))    \n",
    "    \n",
    "    \n",
    "    return input_image, output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image,output_image):\n",
    "#     input_image = tf.image.per_image_standardization(input_image)\n",
    "#     output_image = tf.image.per_image_standardization(output_image)\n",
    "    input_image = input_image/255.0\n",
    "    output_image = output_image/255.0\n",
    "    \n",
    "    return input_image, output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d929e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(input_image_path,output_image_path):\n",
    "    input_image,output_image = load(input_image_path,output_image_path)\n",
    "    input_image,output_image = normalize(input_image,output_image)\n",
    "    \n",
    "    return input_image,output_image\n",
    "\n",
    "def load_image_validation(input_image_path,output_image_path):\n",
    "    input_image,output_image = load(input_image_path,output_image_path)\n",
    "    input_image,output_image = normalize(input_image,output_image)\n",
    "    \n",
    "    return input_image,output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_input_img_path,train_output_img_path))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=16)\n",
    "train_dataset = train_dataset.map(load_image_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_input_img_path,validation_output_img_path))\n",
    "# validation_dataset = validation_dataset.shuffle(buffer_size=16)\n",
    "validation_dataset = validation_dataset.map(load_image_validation,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15273f95",
   "metadata": {},
   "source": [
    "### 4、Building Network Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21365140",
   "metadata": {},
   "source": [
    "#### 4.1、The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "    output = tf.keras.layers.Conv2D(64,3,padding='same',activation='relu')(inputs)\n",
    "    \n",
    "    for layers in range(2,17,1):\n",
    "        output2 = tf.keras.layers.Conv2D(64,3,padding='same',use_bias=False)(output)\n",
    "        output2 = tf.keras.layers.BatchNormalization()(output2)\n",
    "        output2 = tf.keras.layers.Activation('relu')(output2)\n",
    "        output2 = tf.keras.layers.Conv2D(64,3,padding='same',use_bias=False)(output2)\n",
    "        output2 = tf.keras.layers.BatchNormalization()(output2)\n",
    "        output = output + output2\n",
    "        output = tf.keras.layers.Activation('relu')(output)\n",
    "        \n",
    "    output = tf.keras.layers.Conv2D(3,3,padding='same')(output)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9a083",
   "metadata": {},
   "source": [
    "#### 4.2、The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x):\n",
    "    leak=0.2\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ac42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "    output1 = tf.keras.layers.Conv2D(64,3,padding='same',strides=1,activation=lrelu)(inputs)\n",
    "    output2 = tf.keras.layers.Conv2D(64,3,padding='same',strides=2,activation=lrelu)(output1)\n",
    "    output3 = tf.keras.layers.Conv2D(128,3,padding='same',strides=1,activation=lrelu)(output2)\n",
    "    output4 = tf.keras.layers.Conv2D(128,3,padding='same',strides=2,activation=lrelu)(output3)\n",
    "    output5 = tf.keras.layers.Conv2D(256,3,padding='same',strides=1,activation=lrelu)(output4)\n",
    "    output6 = tf.keras.layers.Conv2D(256,3,padding='same',strides=2,activation=lrelu)(output5)\n",
    "    output7 = tf.keras.layers.Conv2D(1,3,padding='same',strides=1,activation='sigmoid')(output6)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=output7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde2e49",
   "metadata": {},
   "source": [
    "### 5、Loss functions of the generator and the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac772f8",
   "metadata": {},
   "source": [
    "#### 5.1、Loss functions of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd9d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVERSARIAL_LOSS_FACTOR = 0.5\n",
    "PSNR_LOSS_FACTOR = -1.0\n",
    "SSIM_LOSS_FACTOR = -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a2099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 255.0\n",
    "    return  10.0 * tf.math.log((max_pixel ** 2) / (tf.reduce_mean(tf.square(y_pred - y_true))))/tf.math.log(10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tf_fspecial_gauss(size, sigma=1.5):\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\"\"\"\n",
    "    x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "\n",
    "    y_data = np.expand_dims(y_data, axis=-1)\n",
    "    y_data = np.expand_dims(y_data, axis=-1)\n",
    "\n",
    "    x = tf.constant(x_data, dtype=tf.float32)\n",
    "    y = tf.constant(y_data, dtype=tf.float32)\n",
    "\n",
    "    g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g / tf.reduce_sum(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f012819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM_one(img1, img2, k1=0.01, k2=0.02, L=1, window_size=11):\n",
    "    \"\"\"\n",
    "    The function is to calculate the ssim score\n",
    "    \"\"\"\n",
    "    img1 = tf.expand_dims(img1, -1)\n",
    "    img2 = tf.expand_dims(img2, -1)\n",
    "\n",
    "    window = _tf_fspecial_gauss(window_size)\n",
    "\n",
    "    mu1 = tf.nn.conv2d(img1, window, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    mu2 = tf.nn.conv2d(img2, window, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "\n",
    "    mu1_sq = mu1 * mu1\n",
    "    mu2_sq = mu2 * mu2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = tf.nn.conv2d(img1*img1, window, strides = [1 ,1, 1, 1], padding = 'VALID') - mu1_sq\n",
    "    sigma2_sq = tf.nn.conv2d(img2*img2, window, strides = [1, 1, 1, 1], padding = 'VALID') - mu2_sq\n",
    "    sigma1_2 = tf.nn.conv2d(img1*img2, window, strides = [1, 1, 1, 1], padding = 'VALID') - mu1_mu2\n",
    "\n",
    "    c1 = (k1*L)**2\n",
    "    c2 = (k2*L)**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + c1)*(2*sigma1_2 + c2)) / ((mu1_sq + mu2_sq + c1)*(sigma1_sq + sigma2_sq + c2))\n",
    "    \n",
    "#     ssim = tf.reduce_mean(ssim_map)\n",
    "#     tf.print(\"ssim:\",ssim)\n",
    "    \n",
    "#     return ssim\n",
    "    \n",
    "    return tf.reduce_mean(ssim_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c871461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM_three(img1, img2):\n",
    "    rgb1 = tf.unstack(img1, axis=3)\n",
    "    r1 = rgb1[0]\n",
    "    g1 = rgb1[1]\n",
    "    b1 = rgb1[2]\n",
    "\n",
    "    rgb2 = tf.unstack(img2, axis=3)\n",
    "    r2 = rgb2[0]\n",
    "    g2 = rgb2[1]\n",
    "    b2 = rgb2[2]\n",
    "\n",
    "    ssim_r = SSIM_one(r1, r2)\n",
    "    ssim_g = SSIM_one(g1, g2)\n",
    "    ssim_b = SSIM_one(b1, b2)\n",
    "\n",
    "    ssim = tf.reduce_mean(ssim_r + ssim_g + ssim_b) / 3\n",
    "    tf.print(\"ssim:\",ssim)\n",
    "    \n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    return ADVERSARIAL_LOSS_FACTOR * tf.reduce_mean(tf.scalar_mul(-1, disc_generated_output)) + \\\n",
    "    PSNR_LOSS_FACTOR * PSNR(target, gen_output) + SSIM_LOSS_FACTOR * SSIM_three(target, gen_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ae526",
   "metadata": {},
   "source": [
    "#### 5.2、Loss functions of the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d247448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    return tf.reduce_mean(disc_real_output) - tf.reduce_mean(disc_generated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a854de",
   "metadata": {},
   "source": [
    "### 6、Optimizer for the generator and the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87974d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.RMSprop(LEARNING_RATE)\n",
    "discriminator_optimizer = tf.keras.optimizers.RMSprop(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd79bdf",
   "metadata": {},
   "source": [
    "### 7、Test and visualize our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01081ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, target):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], target[0], prediction[0],test_input[1], target[1], prediction[1],test_input[2], target[2], prediction[2]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image','Input Image', 'Ground Truth', 'Predicted Image','Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    localtime = time.strftime('%Y_%m_%d_%H_%M_%S_')\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "    plt.savefig('./#########/'+localtime+'image.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db6586",
   "metadata": {},
   "source": [
    "### 8、Training...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "# @tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        \n",
    "#         disc_real_output = discriminator(input_image, training=True)\n",
    "        disc_real_output = discriminator(target, training=True)\n",
    "        disc_generated_output = discriminator(gen_output, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(disc_generated_output,gen_output,target)\n",
    "        disc_loss = discriminator_loss(disc_real_output,disc_generated_output)\n",
    "        \n",
    "        \n",
    "    tf.print('g_loss:',gen_loss,'d_loss:',disc_loss)\n",
    "    \n",
    "#     generator_gradients = gen_tape.gradient(gen_loss,generator.variables)\n",
    "#     discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.variables)\n",
    "    generator_gradients = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "    \n",
    "#     generator_optimizer.apply_gradients(zip(generator_gradients,generator.variables))\n",
    "#     discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.variables))\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        for example_input, example_target in test_ds.take(1):  \n",
    "            generate_images(generator,example_input,example_target)\n",
    "            localtime1 = time.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "            generator.save('./#########/generator_detectpos_{}.h5'.format(localtime1))\n",
    "        print(\"Epoch:\",epoch)\n",
    "        \n",
    "        for n,(input_image,target) in train_ds.enumerate():\n",
    "            print('.',end='')\n",
    "            if (n+1)%100 == 0:\n",
    "                print()\n",
    "            train_step(input_image,target,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7647e",
   "metadata": {},
   "source": [
    "#### training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48253804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b298f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit(train_dataset,EPOCHS,validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
